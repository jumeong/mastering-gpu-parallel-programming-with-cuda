# 25. Query the device properties using the Runtime APIs
## The runtime APIs
- High-level interface to CUDA
- Harness the power of NVIDIA GPUs
- Managing the GPU devices, memory allocation, and execution of parallel kernels
- ëŒ€ë¶€ë¶„ì˜ APIëŠ” cudaError_t êµ¬ì¡°ì²´ë¥¼ returníˆê³ , ì´ì™¸ì— returní•  ê°’ì´ ìˆìœ¼ë©´ í¬ì¸í„° ì…ì¶œë ¥ì„ í†µí•´ ë°˜í™˜í•¨
- https://docs.nvidia.com/cuda/cuda-runtime-api/index.html

## cudaGetDeviceCount()
  - í˜„ì¬ ì‹œìŠ¤í…œì—ì„œ nvidia gpuê°€ ëª‡ ê°œì¸ì§€ ì¡°íšŒ
## cudaGetDeviceProperties()
  - cudaDeviceProp êµ¬ì¡°ì²´ì˜ name, memoryClockRate, regsPerBlock, regsPerMultiprocessor, totalGlobalMem, multiProcessorCount ë“± ì—¬ëŸ¬ê°€ì§€ íŒŒë¼ë¯¸í„°ë¥¼ ì¡°íšŒí•  ìˆ˜ ìˆìŒ

# 26. Nvidia-smi and its configurations (Linux User)
## nvidia-smi (NVIDIA System Management Interface)
```bash
/content# nvidia-smi
Fri Jan 30 15:32:55 2026       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |
| N/A   38C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
```

- Performance monitoring
  - Utilization, memory usage, temperature and power
- Settings management
  - Controlling the clock speed and power limits
- Device information querying
  - GPU name, driver version
- nvidia-smiì—ì„œì˜ CUDA Versionê³¼ nvccì—ì„œì˜ CUDA VersionëŠ” ë‹¤ë¥¼ ìˆ˜ ìˆìŒ!!!
  - ê°•ì‚¬ì˜ í™˜ê²½ì—ì„œëŠ” ë‘ ë²„ì „ì´ ê°™ì•˜ê³ , ì˜ë¯¸í•˜ëŠ” ë°”ê°€ ë‹¤ë¥¸ ê²ƒì„ ì–¸ê¸‰í•˜ì§€ ì•ŠìŒ. 
  - nvidia-smi = â€œì´ GPU ë“œë¼ì´ë²„ë¡œ ì–´ë””ê¹Œì§€ ì‹¤í–‰ ê°€ëŠ¥?â€
  - nvcc = â€œë‚˜ëŠ” ì§€ê¸ˆ ì–´ë–¤ CUDAë¡œ ì»´íŒŒì¼ ì¤‘?â€

- Various Options
  - Monitoring GPUs Continuously
    - command: nvidia-smi -l 5
    - ì‚¬ìš©ìê°€ ëŠê¸° ì „ê¹Œì§€ 5ì´ˆ ê°„ê²©ìœ¼ë¡œ nvidia-smië¥¼ ë°˜ë³µ ì¶œë ¥
  - Displaying Specific Information
    - command: nvidia-smi --query-gpu=gpu_name,driver_version,temperature.gpu --format=csv
    - csv íŒŒì¼ í˜•íƒœë¡œ ì…ë ¥í•œ íŒŒë¼ë¯¸í„°ë¥¼ ì¶œë ¥
  - Setting Power Limits
    - command: nvidia-smi -i 0 -pl 150
    - ì…ë ¥í•œ ê°’ìœ¼ë¡œ Powerë¥¼ ì œí•œ
    - ```bash
      /content# nvidia-smi -i 0 -pl 150
      Provided power limit 150.00 W is not a valid power limit which should be between 60.00 W and 70.00 W for GPU 00000000:00:04.0
      Terminating early due to previous errors.
      ```
  - Persistence mode
    - ê°•ì‚¬ì˜ ì„¤ëª…ì´ Permission modeë¡œ Clockì´ë‚˜ Powerë¥¼ ì¡°ì ˆí•  ë•Œ, ì´ê²ƒì— ë”°ë¼ ì¢Œìš°ë  ìˆ˜ ìˆë‹¤ê³  í•˜ëŠ”ë° í‹€ë¦° ì„¤ëª…ì¸ë“¯...
    - Geminiì˜ ì„¤ëª…
      - **Persistence Modeê°€ í•„ìš”í•œ ì´ìœ **

        ë³´í†µ ë¦¬ëˆ…ìŠ¤ í™˜ê²½ì—ì„œ GPUë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šì„ ë•ŒëŠ” ì „ë ¥ ì†Œëª¨ë¥¼ ì¤„ì´ê¸° ìœ„í•´ ë“œë¼ì´ë²„ê°€ ì–¸ë¡œë“œ(Unload)ë˜ê±°ë‚˜ GPUê°€ íœ´ë©´ ìƒíƒœë¡œ ë“¤ì–´ê°‘ë‹ˆë‹¤. ê·¸ëŸ°ë° ë‹¤ì‹œ ì‘ì—…ì„ ì‹œì‘í•˜ë ¤ê³  í•˜ë©´ ë“œë¼ì´ë²„ë¥¼ ë‹¤ì‹œ ë¶ˆëŸ¬ì˜¤ëŠ” ê³¼ì •ì—ì„œ **ìˆ˜ ì´ˆ ì •ë„ì˜ ì§€ì—°(Latency)**ì´ ë°œìƒí•˜ê²Œ ë˜ì£ .
        
        pm ì˜µì…˜ì€ ì´ ê³¼ì •ì„ ìƒëµí•˜ê³  GPUë¥¼ í•­ìƒ ëŒ€ê¸° ìƒíƒœë¡œ ìœ ì§€í•˜ê²Œ ë§Œë“­ë‹ˆë‹¤.
        
        **ì£¼ìš” íŠ¹ì§• ë° ì¥ì **
        ì‘ë‹µ ì†ë„ í–¥ìƒ: ë“œë¼ì´ë²„ ë¡œë”© ì˜¤ë²„í—¤ë“œê°€ ì—†ì–´ì ¸ì„œ ì»¤ë§¨ë“œ ì‹¤í–‰ì´ë‚˜ ì‘ì—… ì‹œì‘ì´ ì¦‰ê°ì ì…ë‹ˆë‹¤.
        
        ìƒíƒœ ìœ ì§€: GPUì˜ ì„¤ì •ê°’ë“¤ì´ ì‘ì—… ì‚¬ì´ì‚¬ì´ì— ì´ˆê¸°í™”ë˜ì§€ ì•Šë„ë¡ ë„ì™€ì¤ë‹ˆë‹¤.
        
        ì•ˆì •ì„±: ë¹ˆë²ˆí•˜ê²Œ ë“œë¼ì´ë²„ê°€ ë¡œë“œ/ì–¸ë¡œë“œë˜ë©´ì„œ ìƒê¸¸ ìˆ˜ ìˆëŠ” ë¯¸ì„¸í•œ ì˜¤ë¥˜ë¥¼ ë°©ì§€í•©ë‹ˆë‹¤.
 
        **ì‚¬ìš© ë°©ë²•**

        í„°ë¯¸ë„ì—ì„œ ë‹¤ìŒê³¼ ê°™ì€ ëª…ë ¹ì–´ë¡œ ì„¤ì •í•˜ê±°ë‚˜ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        
        í˜„ì¬ ìƒíƒœ í™•ì¸: nvidia-smi -q | grep "Persistence Mode"
        
        ëª¨ë“œ í™œì„±í™” (Enable): nvidia-smi -pm 1
        
        ëª¨ë“œ ë¹„í™œì„±í™” (Disable): nvidia-smi -pm 0
        
        ì°¸ê³ : ìµœê·¼ ìµœì‹  ë“œë¼ì´ë²„ë‚˜ ë°ì´í„°ì„¼í„°ìš© GPU(A100, H100 ë“±)ì—ì„œëŠ” ì´ ê¸°ëŠ¥ì´ Persistence Daemonìœ¼ë¡œ ëŒ€ì²´ë˜ê±°ë‚˜ ê¸°ë³¸ì ìœ¼ë¡œ í™œì„±í™”ë˜ì–´ ìˆëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤. ê°œì¸ìš© PC(RTX ì‹œë¦¬ì¦ˆ)ë³´ë‹¤ëŠ” ì„œë²„ í™˜ê²½ì—ì„œ í›¨ì”¬ ì¤‘ìš”í•˜ê²Œ ë‹¤ë¤„ì§€ëŠ” ì˜µì…˜ì´ì—ìš”.
  - -d ì˜µì…˜
    - -d,   --display=          Display only selected information: MEMORY,
                                UTILIZATION, ECC, TEMPERATURE, POWER, CLOCK,
                                COMPUTE, PIDS, PERFORMANCE, SUPPORTED_CLOCKS,
                                PAGE_RETIREMENT, ACCOUNTING, ENCODER_STATS,
                                SUPPORTED_GPU_TARGET_TEMP, VOLTAGE, FBC_STATS
                                ROW_REMAPPER, RESET_STATUS, GSP_FIRMWARE_VERSION
    - curernt clock, supported clockê³¼ ê°™ì´ íŠ¹ì • ë¶€ë¶„ì„ ì§‘ì–´ì„œ ì¶œë ¥ ê°€ëŠ¥
   
# 27. The GPU's Occupancy and Latency hiding
## cudaDeviceGetAttribute()
- ê°ì¢… Attributeë¥¼ ì§€ì •í•´ì„œ Fetchí•  ìˆ˜ ìˆìŒ
- e.g., cudaDeviceGetAttribute(&maxThreadsPerMP, cudaDevAttrMaxThreadsPerMultiProcessor, device)
  
## Occupancy
- Occupancy is a measure of the utilization of the resources in a GPU
- Theoretical occupancy: the ideal case (active warps per SM / maximum warps per SM)
  ğŸ‘‰ ì •ì  ê°’ (launch configurationìœ¼ë¡œ ê²°ì •)
  - Optimal conditions where there are enough independent tasks.
  - ê°•ì˜ì—ì„œëŠ” max warps per SMì´ 48
  - kernelì˜ Block Sizeë¥¼ 32ì—ì„œ 64ë¡œ ë³€ê²½í•˜ë©´ì„œ Theroetical occupancyê°€ ë‘ë°°ê°€ ë˜ëŠ” ê²ƒì„ ë³´ì—¬ì¤Œ
  - ì´ ê³„ì‚°ì„ í• ë•Œ, SM, Registers, Shared Mem, Warps ë“± Block ìˆ˜ë¥¼ ì œí•œí•˜ëŠ” ì—¬ëŸ¬ ìš”ì†Œì— ì˜í•´ ê³„ì‚°ëœ ê²ƒ ì¤‘ ìµœì†Œë¡œ ê³„ì‚°í•´ì•¼ í•¨.
  - ```bash
    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        82.32
    Achieved Active Warps Per SM           warp        26.34
    ------------------------------- ----------- ------------
    ```
- Achived occupancy: average active warps per cycle / max warps per SM
  ğŸ‘‰ ë™ì  ê°’ (ì‹¤í–‰ ì¤‘ ì‹¤ì œë¡œ ê´€ì¸¡)
  - scenario 1: no memory or dependency
  ```bash
  # for 4 warps
  FMUL
  FMUL
  ISETP
  IMAD
  ```

  | Cycle | FP32 Units 32 Cores | ë¹„ê³  |
  | :--- | :--- | :--- |
  | **1** | **Warp 0: FMUL1** | Warp 0ì˜ ì²« ë²ˆì§¸ FMUL (32ìŠ¤ë ˆë“œ ë™ì‹œ ì²˜ë¦¬) |
  | **2** | **Warp 1: FMUL1** | Warp 1ì˜ ì²« ë²ˆì§¸ FMUL |
  | **3** | **Warp 2: FMUL1** | Warp 2ì˜ ì²« ë²ˆì§¸ FMUL |
  | **4** | **Warp 3: FMUL1** | Warp 3ì˜ ì²« ë²ˆì§¸ FMUL |
  | **5** | **Warp 0: FMUL2** | Warp 0ì˜ ë‘ ë²ˆì§¸ FMUL |
  | **6** | **Warp 1: FMUL2** | Warp 1ì˜ ë‘ ë²ˆì§¸ FMUL |
  | **7** | **Warp 2: FMUL2** | Warp 2ì˜ ë‘ ë²ˆì§¸ FMUL |
  | **8** | **Warp 3: FMUL2** | Warp 3ì˜ ë‘ ë²ˆì§¸ FMUL |
  | **9** | **Warp 0: ISETP** | Warp 0ì˜ ë¹„êµ ì—°ì‚° (Condition Check) |
  | **10** | **Warp 1: ISETP** | Warp 1ì˜ ë¹„êµ ì—°ì‚° |
  | **11** | **Warp 2: ISETP** | Warp 2ì˜ ë¹„êµ ì—°ì‚° |
  | **12** | **Warp 3: ISETP** | Warp 3ì˜ ë¹„êµ ì—°ì‚° |
  | **13** | **Warp 0: IMAD** | Warp 0ì˜ ì •ìˆ˜ ê³±ì…ˆ-ê°€ì‚° (Integer Multiply-Add) |
  | **14** | **Warp 1: IMAD** | Warp 1ì˜ ì •ìˆ˜ ê³±ì…ˆ-ê°€ì‚° |
  | **15** | **Warp 2: IMAD** | Warp 2ì˜ ì •ìˆ˜ ê³±ì…ˆ-ê°€ì‚° |
  | **16** | **Warp 3: IMAD** | Warp 3ì˜ ì •ìˆ˜ ê³±ì…ˆ-ê°€ì‚° |
    
  - scenario 2: memory request, 1 inst. dependency
  ```bash
  # for 4 warps
  FMUL
  ISETP
  LDG.E.SYS
  IMAD (dependent w/ LDG)
  ```

  | Cycle | FP32 Units 32 Cores | ë¹„ê³  |
  | :--- | :--- | :--- |
  | **1** | **Warp 0: FMUL** | Warp 0 ì‹œì‘ |
  | **2** | **Warp 1: FMUL** | Warp 1 ì‹œì‘ |
  | **3** | **Warp 2: FMUL** | Warp 2 ì‹œì‘ |
  | **4** | **Warp 3: FMUL** | Warp 3 ì‹œì‘ |
  | **5** | **Warp 0: ISETP** | Warp 0 ë¹„êµ ì—°ì‚° |
  | **6** | **Warp 1: ISETP** | Warp 1 ë¹„êµ ì—°ì‚° |
  | **7** | **Warp 2: ISETP** | Warp 2 ë¹„êµ ì—°ì‚° |
  | **8** | **Warp 3: ISETP** | Warp 3 ë¹„êµ ì—°ì‚° |
  | **9** | **Warp 0: LDG** | Warp 0 ë©”ëª¨ë¦¬ ìš”ì²­ (Stall ì‹œì‘) |
  | **10** | **Warp 1: LDG** | Warp 1 ë©”ëª¨ë¦¬ ìš”ì²­ |
  | **11** | **Warp 2: LDG** | Warp 2 ë©”ëª¨ë¦¬ ìš”ì²­ |
  | **12** | **Warp 3: LDG** | Warp 3 ë©”ëª¨ë¦¬ ìš”ì²­ |
  | **13** | (Memory Waiting) | Warp 0 ë°ì´í„° ì•„ì§ ì•ˆ ì˜´ (Stall) |
  | **14** | (Memory Waiting) | Warp 1 ë°ì´í„° ì•„ì§ ì•ˆ ì˜´ |
  | **15** | **Warp 0: IMAD** | **Warp 0 ë°ì´í„° ë„ì°©!** (IMAD ì‹¤í–‰) |
  | **16** | **Warp 1: IMAD** | **Warp 1 ë°ì´í„° ë„ì°©!** (IMAD ì‹¤í–‰) |

- Summary
  - High occupancy doesn't always equate to high perforamnce
  - Identifying and understanding occupancy can help us pinpoint performance issues.
  - Low occupancy, on the other hand, suggests that there's a bottleneck preventing the GPU from being fully utilized.
 
## Latency Hiding
- CPUì—ì„œëŠ” dependencyë¥¼ ì¡°ì‚¬í•´ì„œ ê¸°ë‹¤ë¦´ í•„ìš”ê°€ ì—†ëŠ” Instructionì´ ë’¤ìª½ì— ìˆìœ¼ë©´ ìˆœì„œë¥¼ ë°”ê¿”ì„œ ì‹¤í–‰í•´ë²„ë¦¬ê¸°ë„ í•¨ (Out of Order)
- DSPì—ì„œëŠ” ë³´í†µ scratch pad memoryë¥¼ ë‘ê¸° ë•Œë¬¸ì— ì—°ì‚°ê¸° ë¿ë§Œ ì•„ë‹ˆë¼ Load/Store ëª…ë ¹ì–´ê¹Œì§€ Cycleì´ Staticí•¨. ê·¸ë˜ì„œ, OoOë³´ë‹¤ëŠ” Compile ë‹¨ê³„ì—ì„œ VLIWë¡œ ì—¬ëŸ¬ ê°œì˜ ëª…ë ¹ì–´ë¥¼ ë¬¶ì–´ë²„ë ¤ì„œ Latency Hidingì„ í•¨.
- GPUëŠ” dependency ë•Œë¬¸ì— stallë˜ëŠ” warpê°€ ìƒê¸°ë©´ ë‹¤ë¥¸ warpë¡œ context switchingí•´ë²„ë¦°ë‹¤ëŠ” ì² í•™

# 28. Allocated active blocks per SM
- ë™ì‹œì— ì‹¤í–‰ê°€ëŠ¥í•œ block ìˆ˜
- ì—¬ëŸ¬ê°€ì§€ HW ìì›ì— ì˜í•´ ê³„ì‚°ë˜ëŠ” block ìˆ˜ ì¤‘ minimum

## Max Thread blocks/SM
- A100 ê¸°ì¤€ 32ê°œ
  
## Max warps/SM
- A100 ê¸°ì¤€ 64ê°œ
- Thread Blockì˜ Sizeì— ë”°ë¼ ëª‡ê°œì˜ Blockì´ SMì— í• ë‹¹ë ì§€ëŠ” ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŒ
- ì˜ˆë¥¼ ë“¤ì–´, í•œ ê°œ Blockì´ 128 Threads (4 Warps)ë¡œ êµ¬ì„±ëœë‹¤ë©´ ì´ SMì—ëŠ” 16ê°œ Blockë§Œ í• ë‹¹ ê°€ëŠ¥
- í•œ ê°œ Blockì´ 64 Threads (2 Warps)ë¡œ êµ¬ì„±ëœë‹¤ë©´ 32ê°œ Blockìœ¼ë¡œ êµ¬ì„± ê°€ëŠ¥

## Max registers/SM
- A100 ê¸°ì¤€ 64Kê°œ
- 1024 Threadsë¡œ êµ¬ì„±ëœ 1 Blockì„ ê°€ì •, Each thread requires 100 registers.
- thread ìˆ˜ë¥¼ ì¤„ì´ì§€ ì•Šìœ¼ë©´ register spilling ë°œìƒ!
- register spillingì´ ë°œìƒí•˜ë©´ registerê°€ ëª¨ìë¼ë¯€ë¡œ local memoryê¹Œì§€ ëŒì–´ì“°ê²Œ ë¨. local memoryëŠ” registerì— ë¹„í•´ latencyê°€ ëŠë¦¬ë¯€ë¡œ performance degradation

## Shared Memory/SM
- A100 ê¸°ì¤€ up to 164KB

# 29. Starting with the nsight compute

# 30. All profiling tools from NVidia (Nsight systems - compute - nvprof ...)
- CUDA-MEMCHECK
  - Identify and diagnose memory errors in CUDA applications
- CUDA-GDB
- NVIDIA Visual Profiler (nvvp)
  - Detailed timing info and hw counters for CUDA, OpenCL, Direct3D...
  - Graphical view of the applications timelines and achieved occupancy
- NVIDIA Nsight Systems
  - Comprehensive workload level performance
- NVIDIA Nsight Compute
  - Dive into top CUDA kernels by using metrics/counter collection
- NVIDIA Nsight Graphics
  - Detailed frame/render performance

# 31. Error Checking APIs
- Checking erros to ensure Cuda functions operate smoothly.
- Example
  - Application compiles correctly, but fails to execute properly
  - Malfunctioning malloc because no enough space in the memory
- Two catergories
  - Synchronous
  - Asynchronous 
- Usage
  ```cpp
  cudaError_t err = cudaMalloc((void **)&d_A, size);
  if (err != cudaSuccess) {
      fprintf(stderr, "Failed to allocated device memory %s\n", cudaGetErrorString(err));
  }

  cudaError_t err = cudaGetLastError();
  if (err != cudaSuccess) {
      fprintf(stderr, "Kernel launch failed %s\n", cudaGetErrorString(err));
  }
  ```

# 32. Nsight Compute performance using command line analysis
## ë‘ ê°€ì§€ ë¶„ì„ ë°©ë²•

| ë°©ë²• | íŠ¹ì§• | ì‚¬ìš© ì‹œê¸° |
| --- | --- | --- |
| **CLI (Command Line)** | íŠ¹ì • ë©”íŠ¸ë¦­ë§Œ ë¹ ë¥´ê²Œ ìˆ˜ì§‘ | ëª‡ ê°€ì§€ ìˆ˜ì¹˜ë§Œ í™•ì¸í•  ë•Œ |
| **GUI (Graphical)** | Roofline ë¶„ì„, ì°¨íŠ¸, ìƒì„¸ ì‹œê°í™” | ì‹¬ì¸µ ì„±ëŠ¥ ë¶„ì„í•  ë•Œ |

**ê¸°ë³¸ ëª…ë ¹ì–´**
```basah
ncu ./my_cuda_app                    # ê¸°ë³¸ 4ê°œ ì„¹ì…˜ ì¶œë ¥
ncu -o profile ./my_cuda_app         # ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥
```

## Sections (ì„¹ì…˜)

ê¸°ë³¸ ì‹¤í–‰ ì‹œ 4ê°œ ì„¹ì…˜ë§Œ í‘œì‹œë˜ì§€ë§Œ,Â **ì´ 23ê°œ ì„¹ì…˜**ì´ ì¡´ì¬í•¨

### ê¸°ë³¸ 4ê°œ ì„¹ì…˜
| ì„¹ì…˜ | ë‚´ìš© |
| --- | --- |
| **GPU Speed of Light** | DRAM, L1/L2 ìºì‹œ throughput, SM utilization |
| **Launch Statistics** | block size, grid size, registers/thread, shared memory |
| **Occupancy** | theoretical vs achieved occupancy |
| **Memory Workload** | DRAM, L1, L2ì˜ active cycles |

### íŠ¹ì • ì„¹ì…˜ë§Œ ë³´ê¸°
```bash
# Launch Statisticsë§Œ ë³´ê¸°
ncu --section LaunchStats ./my_cuda_app

# Warp State Statistics ë³´ê¸°
ncu --section WarpStateStats ./my_cuda_app
```

### ì£¼ìš” ì„¹ì…˜ ëª©ë¡
| Identifier | ì„¤ëª… |
| --- | --- |
| `SpeedOfLight` | GPU ì „ì²´ throughput |
| `LaunchStats` | ì»¤ë„ ëŸ°ì¹˜ ì •ë³´ |
| `Occupancy` | Warp occupancy |
| `MemoryWorkloadAnalysis` | ë©”ëª¨ë¦¬ ì›Œí¬ë¡œë“œ ìƒì„¸ |
| `WarpStateStats` | Warp ìƒíƒœ í†µê³„ |
| `SchedulerStats` | ìŠ¤ì¼€ì¤„ëŸ¬ í†µê³„ |
| `SourceCounters` | ì†ŒìŠ¤ ë ˆë²¨ ì¹´ìš´í„° |
| `NVLink` | NVLink í†µì‹  ë¶„ì„ |


## Metrics (ë©”íŠ¸ë¦­)

> ğŸ’¡ Nsight Computeì—ëŠ”Â ì•½ 10ë§Œ ê°œì˜ ë©”íŠ¸ë¦­ì´ ìˆìŒ
> ì°¸ê³  : https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metric-collection

### ë©”íŠ¸ë¦­ ì „ì²´ ëª©ë¡ ë³´ê¸°

```bash
ncu --query-metrics-mode all > metrics.txt
```

### ë©”íŠ¸ë¦­ ëª…ëª… ê·œì¹™

```jsx
[í•˜ë“œì›¨ì–´ ìœ ë‹›]__[ë©”íŠ¸ë¦­ëª…].[suffix]
```

**ì˜ˆì‹œ**:Â `dram__bytes.avg`

- `dram`Â = í•˜ë“œì›¨ì–´ ìœ ë‹› (DRAM)
- `bytes`Â = ë©”íŠ¸ë¦­ (ë°”ì´íŠ¸ ìˆ˜)
- `avg`Â = suffix (í‰ê· ê°’)

### í•˜ë“œì›¨ì–´ ìœ ë‹›

| ì ‘ë‘ì–´ | í•˜ë“œì›¨ì–´ |
| --- | --- |
| `dram` | DRAM (ê¸€ë¡œë²Œ ë©”ëª¨ë¦¬) |
| `l1tex` | L1 í…ìŠ¤ì²˜ ìºì‹œ |
| `lts` | L2 ìºì‹œ |
| `sm` | Streaming Multiprocessor |
| `smsp` | SM ë‚´ íŒŒí‹°ì…˜ (SMì˜ 1/4) |
| `gpu` | GPU ì „ì²´ |

### Suffix (ì ‘ë¯¸ì‚¬)

| Suffix | ì˜ë¯¸ |
| --- | --- |
| `.min` | ëª¨ë“  SM ì¤‘ ìµœì†Œê°’ |
| `.max` | ëª¨ë“  SM ì¤‘ ìµœëŒ€ê°’ |
| `.avg` | ëª¨ë“  SMì˜ í‰ê· ê°’ |
| `.sum` | ì „ì²´ GPU í•©ê³„ (= max Ã— SM ê°œìˆ˜) |

**ì˜ˆì‹œ**

- 100ê°œ SMì´ ìˆê³  L2 ìºì‹œ ì‚¬ìš© ì‚¬ì´í´ì´ SMë§ˆë‹¤ ë‹¤ë¥¼ ë•Œ:
    - `.min`Â = ê°€ì¥ ì ê²Œ ì‚¬ìš©í•œ SMì˜ ê°’
    - `.max`Â = ê°€ì¥ ë§ì´ ì‚¬ìš©í•œ SMì˜ ê°’
    - `.avg`Â = ì „ì²´ í‰ê· 
    - `.sum`Â = ì „ì²´ í•©ê³„
 
## ì‹¤ì „ ì‚¬ìš©ë²•

### íŠ¹ì • ë©”íŠ¸ë¦­ ìˆ˜ì§‘

```bash
# L1 ìºì‹œ hit rate
ncu --metrics l1tex__t_sector_hit_rate ./my_app

# ì—¬ëŸ¬ ë©”íŠ¸ë¦­ ë™ì‹œ ìˆ˜ì§‘ (ì‰¼í‘œë¡œ êµ¬ë¶„)
ncu --metrics l1tex__t_sector_hit_rate,lts__t_sector_hit_rate ./my_app

# suffix ìƒëµí•˜ë©´ ëª¨ë“  suffix ìˆ˜ì§‘
ncu --metrics sm__inst_executed ./my_app
# â†’ sm__inst_executed.avg, .max, .min, .sum ëª¨ë‘ ì¶œë ¥

```

### CSVë¡œ ë‚´ë³´ë‚´ê¸°

```bash
ncu --metrics sm__inst_executed --csv ./my_app > output.csv

```

### íŠ¹ì • í•˜ë“œì›¨ì–´ ìœ ë‹›ì˜ ëª¨ë“  ë©”íŠ¸ë¦­ ìˆ˜ì§‘

```bash
# shared memory ê´€ë ¨ ëª¨ë“  ë©”íŠ¸ë¦­
ncu --metrics regex:.*shared.* ./my_app --csv > shared_metrics.csv

# L1 ìºì‹œ ê´€ë ¨ ëª¨ë“  ë©”íŠ¸ë¦­
ncu --metrics regex:.*l1tex.* ./my_app
```

---

## í•µì‹¬ ë©”íŠ¸ë¦­ ì˜ˆì‹œ

### ìºì‹œ ì„±ëŠ¥

```bash
# L1 hit rate (0%ë©´ ë¬¸ì œ!)
ncu --metrics l1tex__t_sector_hit_rate ./my_app

# L2 hit rate
ncu --metrics lts__t_sector_hit_rate ./my_app

```

> âš ï¸ L1 hit rateê°€ 0%ë©´ ëª¨ë“  ë©”ëª¨ë¦¬ ì—°ì‚°ì´ ê¸€ë¡œë²Œ ë©”ëª¨ë¦¬ì—ì„œ ì½ëŠ” ê²ƒ
> â†’ ìˆ˜ë°± ì‚¬ì´í´ vs L1 íˆíŠ¸ ì‹œ ~30 ì‚¬ì´í´

### ëª…ë ¹ì–´ ì‹¤í–‰

```bash
# SMë‹¹ ì‹¤í–‰ëœ ëª…ë ¹ì–´ ìˆ˜
ncu --metrics sm__inst_executed ./my_app

# FP64 (double precision) ëª…ë ¹ì–´
ncu --metrics sm__inst_executed_pipe_fp64 ./my_app

# FP16 (half precision) ëª…ë ¹ì–´
ncu --metrics sm__inst_executed_pipe_fp16 ./my_app
```

### Warp ìƒíƒœ

```bash
ncu --section WarpStateStats ./my_app
```

- `warp_cycles_per_issued_instruction`Â - ëª…ë ¹ì–´ë‹¹ warp ì‚¬ì´í´
- `active threads per warp`Â - warpë‹¹ í™œì„± ìŠ¤ë ˆë“œ (ì´ìƒì : 32)

## ë¶„ì„ íŒ

### .sum ê³„ì‚° ë°©ì‹

```jsx
.sum = .max Ã— SM ê°œìˆ˜

```

**ê²€ì¦ ì˜ˆì‹œ**Â (RTX 3060, 38 SM):

```jsx
sm__inst_executed.sum / sm__inst_executed.avg â‰ˆ 38

```

### Nsight Computeê°€ ì£¼ëŠ” ì¡°ì–¸

ì‹¤í–‰ ê²°ê³¼ì— ìë™ìœ¼ë¡œ ë¶„ì„/ê²½ê³ ê°€ í¬í•¨ë¨:

```jsx
The local speedup is 93%, which is good.
On average each warp stalled for 111 cycles due to scoreboard dependency.

```

â†’ ì´ëŸ° ë©”ì‹œì§€ë¥¼ ì½ê³  ë³‘ëª© íŒŒì•…

---

## Quick Reference

| ëª…ë ¹ì–´ | ìš©ë„ |
| --- | --- |
| `ncu ./app` | ê¸°ë³¸ 4ê°œ ì„¹ì…˜ ë¶„ì„ |
| `ncu --section <name> ./app` | íŠ¹ì • ì„¹ì…˜ë§Œ |
| `ncu --metrics <metric> ./app` | íŠ¹ì • ë©”íŠ¸ë¦­ ìˆ˜ì§‘ |
| `ncu --metrics regex:.*<pattern>.* ./app` | íŒ¨í„´ ë§¤ì¹­ ë©”íŠ¸ë¦­ |
| `ncu --csv ./app > out.csv` | CSV ì¶œë ¥ |
| `ncu --query-metrics-mode all` | ì „ì²´ ë©”íŠ¸ë¦­ ëª©ë¡ |
| `ncu -o profile ./app` | ê²°ê³¼ íŒŒì¼ ì €ì¥ (GUIì—ì„œ ì—´ê¸°) |

---

## í•µì‹¬ í¬ì¸íŠ¸

**ì„¹ì…˜ vs ë©”íŠ¸ë¦­**
- ì„¹ì…˜: ê´€ë ¨ ë©”íŠ¸ë¦­ë“¤ì˜ ê·¸ë£¹ (ì˜ˆ: Launch Statistics)
- ë©”íŠ¸ë¦­: ê°œë³„ ì¸¡ì •ê°’ (ì˜ˆ: block size, register count)

**10ë§Œ ê°œ ë©”íŠ¸ë¦­?**

- ì‹¤ì œë¡œ ë‹¤ ë³¼ í•„ìš” ì—†ìŒ
- ëª…ëª… ê·œì¹™ë§Œ ì•Œë©´ 1ë¶„ì— 100ê°œ ë©”íŠ¸ë¦­ íŒŒì•… ê°€ëŠ¥
- í•˜ë“œì›¨ì–´ ìœ ë‹› + ë©”íŠ¸ë¦­ëª… + suffix êµ¬ì¡°

**ì‹¤ì „ì—ì„œ ìì£¼ ë³´ëŠ” ê²ƒ**

- L1/L2 hit rate â†’ ìºì‹œ íš¨ìœ¨
- SM utilization â†’ GPU í™œìš©ë„
- Occupancy â†’ Warp ìŠ¤ì¼€ì¤„ë§ íš¨ìœ¨
- inst_executed â†’ ì‹¤ì œ ì‹¤í–‰ëœ ëª…ë ¹ì–´

### ë°ëª¨ ì‹œë‚˜ë¦¬ì˜¤

- `ncu ./vector_add`Â ì‹¤í–‰í•´ì„œ ê¸°ë³¸ 4ê°œ ì„¹ì…˜ ë³´ì—¬ì£¼ê¸°
- L1 hit rate 0% ë‚˜ì˜¤ëŠ” ê±° ë³´ì—¬ì£¼ê¸° â†’ "ì´ê±´ ë¬¸ì œë‹¤"
- `-csv`ë¡œ Excelì—ì„œ ì—´ì–´ë³´ê¸°

### ë‹¤ìŒ ê°•ì˜ ì˜ˆê³ 

- block/thread ìˆ˜ ë³€ê²½ì´ ì‹¤í–‰ ì‹œê°„ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ ë¶„ì„
- GUI ë¶„ì„ ìƒì„¸ ì„¤ëª…

## ì‹¤ìŠµ ì˜ˆì œ

CLI ë¶„ì„ ì—°ìŠµìš© ì˜ˆì œ:

### 01_vector_add_[basic.cu](http://basic.cu/)

ê¸°ë³¸ Memory Bound ì»¤ë„. CLI ì‚¬ìš©ë²• ìµíˆê¸°ì— ì í•©.

```bash
# ê¸°ë³¸ 4ê°œ ì„¹ì…˜ í™•ì¸
ncu ./01_basic

# íŠ¹ì • ì„¹ì…˜ë§Œ
ncu --section LaunchStats ./01_basic
ncu --section SpeedOfLight ./01_basic

# íŠ¹ì • ë©”íŠ¸ë¦­
ncu --metrics l1tex__t_sector_hit_rate,lts__t_sector_hit_rate ./01_basic

# CSV ì¶œë ¥
ncu --metrics dram__bytes.sum --csv ./01_basic > bandwidth.csv

# GUIìš© íŒŒì¼ ì €ì¥
ncu -o 01_basic_profile ./01_basic

```

### 05_error_[cases.cu](http://cases.cu/)

ì˜ë„ì ìœ¼ë¡œ ì—ëŸ¬ë¥¼ ë°œìƒì‹œí‚¤ëŠ” 6ê°€ì§€ ì¼€ì´ìŠ¤. ncuê°€ ì—ëŸ¬ë¥¼ ì–´ë–»ê²Œ ë³´ê³ í•˜ëŠ”ì§€ í™•ì¸:

```bash
# ê° ì¼€ì´ìŠ¤ë³„ë¡œ ì‹¤í–‰
./05_error 1  # Invalid grid size
./05_error 2  # Invalid block size
./05_error 3  # Too many threads
./05_error 4  # Out of memory
./05_error 5  # Invalid device
./05_error 6  # Kernel timeout

# ncuë¡œ í”„ë¡œíŒŒì¼ë§ ì‹œë„ (ì—ëŸ¬ ë©”ì‹œì§€ í™•ì¸)
ncu ./05_error 3
```

# 33. Graphical Nsight Compute (windows and linux)
# Nsight Compute GUI ë¶„ì„

NVIDIA Nsight Compute ê·¸ë˜í”½ ì¸í„°í˜ì´ìŠ¤ë¥¼ ì‚¬ìš©í•œ ì‹¬ì¸µ ì„±ëŠ¥ ë¶„ì„

---

## CLI vs GUI

| ë°©ë²• | ì¥ì  | ë‹¨ì  |
| --- | --- | --- |
| **CLI** | ë¹ ë¥¸ ë©”íŠ¸ë¦­ ìˆ˜ì§‘, ìŠ¤í¬ë¦½íŠ¸ ìë™í™” | ì‹œê°í™” ì—†ìŒ |
| **GUI** | ê·¸ë˜í”„/ì°¨íŠ¸, ì˜ì¡´ì„± ì‹œê°í™”, ì¡°ì–¸ ì œê³µ | ì„¤ì • í•„ìš” |

> ğŸ’¡ ë‘˜ ë‹¤ ê°™ì€ ë©”íŠ¸ë¦­ì„ ìˆ˜ì§‘í•˜ì§€ë§Œ, GUIëŠ”Â ì‹œê°í™”ì™€Â ìë™ ë¶„ì„/ì¡°ì–¸ì´ í•µì‹¬ ì°¨ë³„ì 
> 

---

## ì„¤ì¹˜ ë° ì‹¤í–‰

**ì„¤ì¹˜**

- CUDA Toolkit ì„¤ì¹˜ ì‹œ ìë™ í¬í•¨
- ë³„ë„ ì„¤ì¹˜: NVIDIA ì›¹ì‚¬ì´íŠ¸ì—ì„œ "Nsight Compute" ë‹¤ìš´ë¡œë“œ

**í”„ë¡œíŒŒì¼ë§ ì‹œì‘**

```bash
# 1. ì‹¤í–‰íŒŒì¼ ì»´íŒŒì¼
nvcc -o my_app.exe my_kernel.cu

# 2. í”„ë¡œì„¸ìŠ¤ë¥¼ ì¼ì‹œì •ì§€ ìƒíƒœë¡œ ì‹œì‘
ncu --mode launch ./my_app.exe

# 3. GUIì—ì„œ Attach â†’ í”„ë¡œì„¸ìŠ¤ ì„ íƒ â†’ Profile Kernel

```

**GUI ì›Œí¬í”Œë¡œìš°**

1. File â†’ New Project
2. Application Executable ê²½ë¡œ ì„¤ì •
3. Working Directory ì„¤ì •
4. í”„ë¡œì„¸ìŠ¤ Attach
5. Metrics Selectionì—ì„œ ë¶„ì„í•  ì„¹ì…˜ ì„ íƒ
6. Profile Kernel í´ë¦­

## Metrics Selection

í”„ë¡œíŒŒì¼ë§ ì „ì— ìˆ˜ì§‘í•  ì„¹ì…˜ ì„ íƒ:

| ì„¹ì…˜ | ë‚´ìš© |
| --- | --- |
| **Speed of Light Throughput** | SM/ë©”ëª¨ë¦¬ throughput |
| **Roofline Chart** | Compute vs Memory bound ì‹œê°í™” |
| **Compute Workload Analysis** | ì—°ì‚° ìœ ë‹›ë³„ í™œìš©ë„ |
| **Memory Workload Analysis** | ë©”ëª¨ë¦¬ ê³„ì¸µ ê°„ ë°ì´í„° íë¦„ |
| **Scheduler Statistics** | Warp ìŠ¤ì¼€ì¤„ë§ í†µê³„ |
| **Warp State Statistics** | Warp stall ì›ì¸ ë¶„ì„ |
| **Instruction Statistics** | ëª…ë ¹ì–´ë³„ ì‹¤í–‰ íšŸìˆ˜ |
| **Occupancy** | Warp occupancy ë¶„ì„ |

---

## í•µì‹¬ ë¶„ì„ í™”ë©´

### 1. Summary íƒ­

ê¸°ë³¸ ì •ë³´ ìš”ì•½:

- Achieved Occupancy (ì˜ˆ: 81%)
- Theoretical Occupancy (ì˜ˆ: 100%)
- ì£¼ìš” ë³‘ëª© ìš”ì•½

### 2. Details íƒ­ (ê°€ì¥ ì¤‘ìš”)

View â†’Â **Expand Sections**ë¡œ ê·¸ë˜í”„ í™œì„±í™”

---

## GPU Speed of Light

**Compute vs Memory Bound íŒë‹¨**

```jsx
Compute Throughput: 16%  â† ë‚®ìŒ
Memory Throughput:  95%  â† ë†’ìŒ

```

â†’Â **Memory Bound**Â ì• í”Œë¦¬ì¼€ì´ì…˜

**í•´ì„**

- Memory 95%: ëŒ€ë¶€ë¶„ì˜ ì‹œê°„ì„ ë©”ëª¨ë¦¬ ì—°ì‚°ì— ì‚¬ìš©
- Compute 16%: ALUë¥¼ ê±°ì˜ í™œìš©í•˜ì§€ ëª»í•¨
- ëª©í‘œ: Memory throughput â†“, Compute throughput â†‘

---

## Memory Workload Analysis

ë©”ëª¨ë¦¬ ê³„ì¸µ ê°„ ë°ì´í„° íë¦„ ì‹œê°í™”:

```jsx
[SM] â†’ 3.15M requests â†’ [L1 Cache] â†’ [L2 Cache] â†’ [DRAM]
                         Hit: 0%      Hit: 33%
ì´ê±° ì‹¤ì œê·¸ë¦¼ìœ¼ë¡œ ë°”ê¾¸ë©´ ì¢‹ì„ë“¯...
```

**ì°¨íŠ¸ ìƒ‰ìƒ ì˜ë¯¸**

- ğŸŸ¢ ë°ì€ìƒ‰: ë†’ì€ í™œìš©ë„ (peakì— ê°€ê¹Œì›€)
- ğŸ”´ ì–´ë‘ìš´ìƒ‰: ë‚®ì€ í™œìš©ë„

**ë°ì´í„° ì „ì†¡ëŸ‰**

- L2 â†’ L1: 268MB (ì½ê¸°: vector A, B)
- L1 â†’ L2: 134MB (ì“°ê¸°: vector C)
- ì½ê¸°ê°€ ì“°ê¸°ì˜ 2ë°° = 2ê°œ ì½ê³  1ê°œ ì”€

**ë¬¸ì œ ì§„ë‹¨**

- L1 hit rate 0% â†’ ëª¨ë“  ìš”ì²­ì´ L2 ì´ìƒìœ¼ë¡œ ê°
- L2 hit rate 33% â†’ 2/3ê°€ DRAMê¹Œì§€ ê°
- Memory bandwidth 95% â†’ DRAM ì ‘ê·¼ ê³¼ë‹¤

## Compute Workload Analysis

ì—°ì‚° ìœ ë‹›ë³„ í™œìš©ë„:

| ìœ ë‹› | Active Cycles % | Peak Instructions % |
| --- | --- | --- |
| **Load/Store** | - | 16% â† ê°€ì¥ ë†’ìŒ |
| **FMA**Â (Fused Multiply-Add) | 3.55% | - |
| **ALU**Â (Int, FP32, FP16 ë“±) | 4% | - |
| **FP64** | 0% | - |
| **Tensor** | 0% | - |

â†’ Load/Storeê°€ ì§€ë°°ì  =Â **Memory Bound í™•ì¸**

---

## Warp State Statistics

**Stall ì›ì¸ ë¶„ì„**

```jsx
Warp Cycles per Issued Instruction: 119 cycles
Stall Long Scoreboard: 111 cycles (93%)

```

**í•´ì„**

- ë§¤ ëª…ë ¹ì–´ ë°œí–‰ë§ˆë‹¤ warpê°€ í‰ê·  119 ì‚¬ì´í´ ëŒ€ê¸°
- 111 ì‚¬ì´í´ì€Â **scoreboard dependency**Â ë•Œë¬¸
- Scoreboard dependency = ì´ì „ ë©”ëª¨ë¦¬ ë¡œë“œ ê²°ê³¼ë¥¼ ê¸°ë‹¤ë¦¼

**Nsight Compute ì¡°ì–¸ ì˜ˆì‹œ**

> "On average each warp stalled for 111 cycles waiting for scoreboard dependency on L1 texture cache"

â†’ ë©”ëª¨ë¦¬ ì§€ì—°ì´ stallì˜ ì£¼ì›ì¸

## Source íƒ­: ì–´ì…ˆë¸”ë¦¬ ë¶„ì„

CUDA ì½”ë“œì™€ SASS (ì–´ì…ˆë¸”ë¦¬) ë§¤í•‘:

```c
// CUDA ì½”ë“œ
int i = blockIdx.x * blockDim.x + threadIdx.x;
if (i < n) {
    C[i] = A[i] + B[i];
}

```

```jsx
// SASS ì–´ì…ˆë¸”ë¦¬
S2R R0, SR_TID.X      // threadIdx.x ì½ê¸°
S2R R1, SR_CTAID.X    // blockIdx.x ì½ê¸°
IMAD R6, R1, R2, R0   // i = blockIdx.x * blockDim.x + threadIdx.x
LDG R4, [R8]          // A[i] ë¡œë“œ
LDG R3, [R10]         // B[i] ë¡œë“œ
FADD R9, R4, R3       // A[i] + B[i]  â† 93% stall ì›ì¸!
STG [R12], R9         // C[i] ì €ì¥

```

**ì˜ì¡´ì„± ì‹œê°í™”**

- `FADD R9, R4, R3`ëŠ” R4(A[i])ì™€ R3(B[i])ì— ì˜ì¡´
- R4ëŠ”Â `LDG R4`Â ì™„ë£Œë¥¼ ê¸°ë‹¤ë ¤ì•¼ í•¨
- R3ëŠ”Â `LDG R3`Â ì™„ë£Œë¥¼ ê¸°ë‹¤ë ¤ì•¼ í•¨
- â†’Â **Loadê°€ ëë‚  ë•Œê¹Œì§€ Add ë¶ˆê°€ëŠ¥**

**GUIì—ì„œ í™•ì¸**

- âš ï¸ ì•„ì´ì½˜: stall ì›ì¸ ëª…ë ¹ì–´
- ì‚¼ê°í˜• í™”ì‚´í‘œ: ì˜ì¡´ì„± ë°©í–¥ í‘œì‹œ
- ë§ˆìš°ìŠ¤ ì˜¤ë²„: "This line is responsible for 84% of all warp stalls"

## Occupancy ë¶„ì„

**í˜„ì¬ ìƒíƒœ**

- Theoretical: 100%
- Achieved: 81%

**Occupancy Calculator ê·¸ë˜í”„**

Registers per Thread:

```jsx
í˜„ì¬: 16 registers â†’ 48% occupancy
40 registersê¹Œì§€ ì¦ê°€í•´ë„ occupancy ìœ ì§€
40+ registers â†’ occupancy ê°ì†Œ ì‹œì‘

```

Block Size:

```jsx
í˜„ì¬: 96 threads/block
128ê¹Œì§€ ì¦ê°€ â†’ ì˜í–¥ ì—†ìŒ
224+ â†’ occupancy ê°ì†Œ ì‹œì‘
800+ â†’ ì‹¬ê°í•œ ê°ì†Œ (48% â†’ 24%)
```

Shared Memory:

```jsx
í˜„ì¬: 0 bytes (shared memory ë¯¸ì‚¬ìš©)
ì¦ê°€ ì‹œ â†’ occupancy ê°ì†Œ
```

---

## API Statistics íƒ­

CUDA Runtime APIë³„ ì†Œìš” ì‹œê°„:

| API | ì‹œê°„ | ì„¤ëª… |
| --- | --- | --- |
| `cudaMemcpy` | 40ms | CPUâ†”GPU ë°ì´í„° ì „ì†¡ |
| `cudaMalloc` | 7ms | GPU ë©”ëª¨ë¦¬ í• ë‹¹ |
| `cudaFree` | - | GPU ë©”ëª¨ë¦¬ í•´ì œ |
| `cudaLaunchKernel` | - | ì»¤ë„ ì‹¤í–‰ |

â†’ ì»¤ë„ ì‹¤í–‰ ì‹œê°„ ì™¸ì—Â **ë°ì´í„° ì „ì†¡ ì˜¤ë²„í—¤ë“œ**Â íŒŒì•… ê°€ëŠ¥

## ì‹¤ìŠµ ì˜ˆì œ

ê° ë¶„ì„ ê°œë…ì„ ì‹¤ìŠµí•  ìˆ˜ ìˆëŠ” ì˜ˆì œ ì½”ë“œ:

| ì˜ˆì œ | í•™ìŠµ ëª©í‘œ | ê´€ë ¨ ì„¹ì…˜ |
| --- | --- | --- |
| `01_vector_add_basic.cu` | Memory Bound ì»¤ë„ ë¶„ì„ | GPU Speed of Light, Memory Workload |
| `02_compute_bound.cu` | Compute Bound ì»¤ë„ ë¶„ì„ (FMA ì§‘ì•½) | Compute Workload Analysis |
| `03_shared_memory.cu` | Global vs Shared Memory ìºì‹œ íš¨ìœ¨ ë¹„êµ | Memory Workload, L1/L2 Hit Rate |
| `04_occupancy_test.cu` | Block Size, Register ìˆ˜ê°€ Occupancyì— ë¯¸ì¹˜ëŠ” ì˜í–¥ | Occupancy Calculator |
| `06_warp_stall.cu` | Scoreboard, Branch Divergence, Barrier Stall ì›ì¸ ë¶„ì„ | Warp State Statistics, Source íƒ­ |
| `07_memory_coalescing.cu` | Coalesced vs Strided Access íŒ¨í„´ ë¹„êµ | Memory Workload, DRAM Throughput |

### ì‹¤ìŠµ ìˆœì„œ ê¶Œì¥

```bash
# 1. Memory Bound ê¸°ë³¸ (GUI ìµìˆ™í•´ì§€ê¸°)
ncu -o 01_basic ./01_basic
# â†’ Speed of Lightì—ì„œ Memory > Compute í™•ì¸

# 2. Compute Bound ë¹„êµ
ncu -o 02_compute ./02_compute
# â†’ Speed of Lightì—ì„œ Compute > Memory í™•ì¸

# 3. Shared Memory íš¨ê³¼
ncu -o 03_shared ./03_shared
# â†’ L1 Hit Rate ë¹„êµ (global vs shared)

# 4. Occupancy ì‹¤í—˜
ncu --section Occupancy ./04_occupancy 64   # block size 64
ncu --section Occupancy ./04_occupancy 256  # block size 256
ncu --section Occupancy ./04_occupancy 1024 # block size 1024
# â†’ Occupancy Calculator ê·¸ë˜í”„ì™€ ë¹„êµ

# 5. Warp Stall ë¶„ì„
ncu --section WarpStateStats -o 06_stall ./06_warp_stall
# â†’ Source íƒ­ì—ì„œ stall ì›ì¸ ëª…ë ¹ì–´ í™•ì¸

# 6. Memory Coalescing
ncu -o 07_coalesced ./07_coalescing coalesced
ncu -o 07_strided ./07_coalescing strided
# â†’ DRAM Throughput ë¹„êµ

```

---
