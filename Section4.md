# 25. Query the device properties using the Runtime APIs
## The runtime APIs
- High-level interface to CUDA
- Harness the power of NVIDIA GPUs
- Managing the GPU devices, memory allocation, and execution of parallel kernels
- ëŒ€ë¶€ë¶„ì˜ APIëŠ” cudaError_t êµ¬ì¡°ì²´ë¥¼ returníˆê³ , ì´ì™¸ì— returní•  ê°’ì´ ìˆìœ¼ë©´ í¬ì¸í„° ì…ì¶œë ¥ì„ í†µí•´ ë°˜í™˜í•¨
- https://docs.nvidia.com/cuda/cuda-runtime-api/index.html

## cudaGetDeviceCount()
  - í˜„ì¬ ì‹œìŠ¤í…œì—ì„œ nvidia gpuê°€ ëª‡ ê°œì¸ì§€ ì¡°íšŒ
## cudaGetDeviceProperties()
  - cudaDeviceProp êµ¬ì¡°ì²´ì˜ name, memoryClockRate, regsPerBlock, regsPerMultiprocessor, totalGlobalMem, multiProcessorCount ë“± ì—¬ëŸ¬ê°€ì§€ íŒŒë¼ë¯¸í„°ë¥¼ ì¡°íšŒí•  ìˆ˜ ìˆìŒ

# 26. Nvidia-smi and its configurations (Linux User)
## nvidia-smi (NVIDIA System Management Interface)
```bash
/content# nvidia-smi
Fri Jan 30 15:32:55 2026       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |
| N/A   38C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
```

- Performance monitoring
  - Utilization, memory usage, temperature and power
- Settings management
  - Controlling the clock speed and power limits
- Device information querying
  - GPU name, driver version
- nvidia-smiì—ì„œì˜ CUDA Versionê³¼ nvccì—ì„œì˜ CUDA VersionëŠ” ë‹¤ë¥¼ ìˆ˜ ìˆìŒ!!!
  - ê°•ì‚¬ì˜ í™˜ê²½ì—ì„œëŠ” ë‘ ë²„ì „ì´ ê°™ì•˜ê³ , ì˜ë¯¸í•˜ëŠ” ë°”ê°€ ë‹¤ë¥¸ ê²ƒì„ ì–¸ê¸‰í•˜ì§€ ì•ŠìŒ. 
  - nvidia-smi = â€œì´ GPU ë“œë¼ì´ë²„ë¡œ ì–´ë””ê¹Œì§€ ì‹¤í–‰ ê°€ëŠ¥?â€
  - nvcc = â€œë‚˜ëŠ” ì§€ê¸ˆ ì–´ë–¤ CUDAë¡œ ì»´íŒŒì¼ ì¤‘?â€

- Various Options
  - Monitoring GPUs Continuously
    - command: nvidia-smi -l 5
    - ì‚¬ìš©ìê°€ ëŠê¸° ì „ê¹Œì§€ 5ì´ˆ ê°„ê²©ìœ¼ë¡œ nvidia-smië¥¼ ë°˜ë³µ ì¶œë ¥
  - Displaying Specific Information
    - command: nvidia-smi --query-gpu=gpu_name,driver_version,temperature.gpu --format=csv
    - csv íŒŒì¼ í˜•íƒœë¡œ ì…ë ¥í•œ íŒŒë¼ë¯¸í„°ë¥¼ ì¶œë ¥
  - Setting Power Limits
    - command: nvidia-smi -i 0 -pl 150
    - ì…ë ¥í•œ ê°’ìœ¼ë¡œ Powerë¥¼ ì œí•œ
    - ```bash
      /content# nvidia-smi -i 0 -pl 150
      Provided power limit 150.00 W is not a valid power limit which should be between 60.00 W and 70.00 W for GPU 00000000:00:04.0
      Terminating early due to previous errors.
      ```
  - Persistence mode
    - ê°•ì‚¬ì˜ ì„¤ëª…ì´ Permission modeë¡œ Clockì´ë‚˜ Powerë¥¼ ì¡°ì ˆí•  ë•Œ, ì´ê²ƒì— ë”°ë¼ ì¢Œìš°ë  ìˆ˜ ìˆë‹¤ê³  í•˜ëŠ”ë° í‹€ë¦° ì„¤ëª…ì¸ë“¯...
    - Geminiì˜ ì„¤ëª…
      - **Persistence Modeê°€ í•„ìš”í•œ ì´ìœ **

        ë³´í†µ ë¦¬ëˆ…ìŠ¤ í™˜ê²½ì—ì„œ GPUë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šì„ ë•ŒëŠ” ì „ë ¥ ì†Œëª¨ë¥¼ ì¤„ì´ê¸° ìœ„í•´ ë“œë¼ì´ë²„ê°€ ì–¸ë¡œë“œ(Unload)ë˜ê±°ë‚˜ GPUê°€ íœ´ë©´ ìƒíƒœë¡œ ë“¤ì–´ê°‘ë‹ˆë‹¤. ê·¸ëŸ°ë° ë‹¤ì‹œ ì‘ì—…ì„ ì‹œì‘í•˜ë ¤ê³  í•˜ë©´ ë“œë¼ì´ë²„ë¥¼ ë‹¤ì‹œ ë¶ˆëŸ¬ì˜¤ëŠ” ê³¼ì •ì—ì„œ **ìˆ˜ ì´ˆ ì •ë„ì˜ ì§€ì—°(Latency)**ì´ ë°œìƒí•˜ê²Œ ë˜ì£ .
        
        pm ì˜µì…˜ì€ ì´ ê³¼ì •ì„ ìƒëµí•˜ê³  GPUë¥¼ í•­ìƒ ëŒ€ê¸° ìƒíƒœë¡œ ìœ ì§€í•˜ê²Œ ë§Œë“­ë‹ˆë‹¤.
        
        **ì£¼ìš” íŠ¹ì§• ë° ì¥ì **
        ì‘ë‹µ ì†ë„ í–¥ìƒ: ë“œë¼ì´ë²„ ë¡œë”© ì˜¤ë²„í—¤ë“œê°€ ì—†ì–´ì ¸ì„œ ì»¤ë§¨ë“œ ì‹¤í–‰ì´ë‚˜ ì‘ì—… ì‹œì‘ì´ ì¦‰ê°ì ì…ë‹ˆë‹¤.
        
        ìƒíƒœ ìœ ì§€: GPUì˜ ì„¤ì •ê°’ë“¤ì´ ì‘ì—… ì‚¬ì´ì‚¬ì´ì— ì´ˆê¸°í™”ë˜ì§€ ì•Šë„ë¡ ë„ì™€ì¤ë‹ˆë‹¤.
        
        ì•ˆì •ì„±: ë¹ˆë²ˆí•˜ê²Œ ë“œë¼ì´ë²„ê°€ ë¡œë“œ/ì–¸ë¡œë“œë˜ë©´ì„œ ìƒê¸¸ ìˆ˜ ìˆëŠ” ë¯¸ì„¸í•œ ì˜¤ë¥˜ë¥¼ ë°©ì§€í•©ë‹ˆë‹¤.
 
        **ì‚¬ìš© ë°©ë²•**

        í„°ë¯¸ë„ì—ì„œ ë‹¤ìŒê³¼ ê°™ì€ ëª…ë ¹ì–´ë¡œ ì„¤ì •í•˜ê±°ë‚˜ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        
        í˜„ì¬ ìƒíƒœ í™•ì¸: nvidia-smi -q | grep "Persistence Mode"
        
        ëª¨ë“œ í™œì„±í™” (Enable): nvidia-smi -pm 1
        
        ëª¨ë“œ ë¹„í™œì„±í™” (Disable): nvidia-smi -pm 0
        
        ì°¸ê³ : ìµœê·¼ ìµœì‹  ë“œë¼ì´ë²„ë‚˜ ë°ì´í„°ì„¼í„°ìš© GPU(A100, H100 ë“±)ì—ì„œëŠ” ì´ ê¸°ëŠ¥ì´ Persistence Daemonìœ¼ë¡œ ëŒ€ì²´ë˜ê±°ë‚˜ ê¸°ë³¸ì ìœ¼ë¡œ í™œì„±í™”ë˜ì–´ ìˆëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤. ê°œì¸ìš© PC(RTX ì‹œë¦¬ì¦ˆ)ë³´ë‹¤ëŠ” ì„œë²„ í™˜ê²½ì—ì„œ í›¨ì”¬ ì¤‘ìš”í•˜ê²Œ ë‹¤ë¤„ì§€ëŠ” ì˜µì…˜ì´ì—ìš”.
  - -d ì˜µì…˜
    - -d,   --display=          Display only selected information: MEMORY,
                                UTILIZATION, ECC, TEMPERATURE, POWER, CLOCK,
                                COMPUTE, PIDS, PERFORMANCE, SUPPORTED_CLOCKS,
                                PAGE_RETIREMENT, ACCOUNTING, ENCODER_STATS,
                                SUPPORTED_GPU_TARGET_TEMP, VOLTAGE, FBC_STATS
                                ROW_REMAPPER, RESET_STATUS, GSP_FIRMWARE_VERSION
    - curernt clock, supported clockê³¼ ê°™ì´ íŠ¹ì • ë¶€ë¶„ì„ ì§‘ì–´ì„œ ì¶œë ¥ ê°€ëŠ¥
   
# 27. The GPU's Occupancy and Latency hiding
## cudaDeviceGetAttribute()
- ê°ì¢… Attributeë¥¼ ì§€ì •í•´ì„œ Fetchí•  ìˆ˜ ìˆìŒ
- e.g., cudaDeviceGetAttribute(&maxThreadsPerMP, cudaDevAttrMaxThreadsPerMultiProcessor, device)
  
## Occupancy
- Occupancy is a measure of the utilization of the resources in a GPU
- Theoretical occupancy: the ideal case (warp used in a kernel / max warps per SM)
  - Optimal conditions where there are enough independent tasks.
  - ê°•ì˜ì—ì„œëŠ” max warps per SMì´ 48
  - kernelì˜ Block Sizeë¥¼ 32ì—ì„œ 64ë¡œ ë³€ê²½í•˜ë©´ì„œ Theroetical occupancyê°€ ë‘ë°°ê°€ ë˜ëŠ” ê²ƒì„ ë³´ì—¬ì¤Œ
  - ì´ ê³„ì‚°ì„ í• ë•Œ, SM, Registers, Shared Mem, Warps ë“± Block ìˆ˜ë¥¼ ì œí•œí•˜ëŠ” ì—¬ëŸ¬ ìš”ì†Œì— ì˜í•´ ê³„ì‚°ëœ ê²ƒ ì¤‘ ìµœì†Œë¡œ ê³„ì‚°í•´ì•¼ í•¨.
  - ```bash
    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        82.32
    Achieved Active Warps Per SM           warp        26.34
    ------------------------------- ----------- ------------
    ```
- Achived occupancy: the actual usage of the GPU's resources
  - scenario 1: no memory or dependency
  ```bash
  # for 4 warps
  FMUL
  FMUL
  ISETP
  IMAD
  ```

  | Cycle | FP32 Units (32 Cores ê°€ì •) | ë¹„ê³  |
  | :--- | :--- | :--- |
  | **1** | **Warp 0: FMUL1** | Warp 0ì˜ ì²« ë²ˆì§¸ FMUL (32ìŠ¤ë ˆë“œ ë™ì‹œ ì²˜ë¦¬) |
  | **2** | **Warp 1: FMUL1** | Warp 1ì˜ ì²« ë²ˆì§¸ FMUL |
  | **3** | **Warp 2: FMUL1** | Warp 2ì˜ ì²« ë²ˆì§¸ FMUL |
  | **4** | **Warp 3: FMUL1** | Warp 3ì˜ ì²« ë²ˆì§¸ FMUL |
  | **5** | **Warp 0: FMUL2** | Warp 0ì˜ ë‘ ë²ˆì§¸ FMUL |
  | **6** | **Warp 1: FMUL2** | Warp 1ì˜ ë‘ ë²ˆì§¸ FMUL |
  | **7** | **Warp 2: FMUL2** | Warp 2ì˜ ë‘ ë²ˆì§¸ FMUL |
  | **8** | **Warp 3: FMUL2** | Warp 3ì˜ ë‘ ë²ˆì§¸ FMUL |
  | **9** | **Warp 0: ISETP** | Warp 0ì˜ ë¹„êµ ì—°ì‚° (Condition Check) |
  | **10** | **Warp 1: ISETP** | Warp 1ì˜ ë¹„êµ ì—°ì‚° |
  | **11** | **Warp 2: ISETP** | Warp 2ì˜ ë¹„êµ ì—°ì‚° |
  | **12** | **Warp 3: ISETP** | Warp 3ì˜ ë¹„êµ ì—°ì‚° |
  | **13** | **Warp 0: IMAD** | Warp 0ì˜ ì •ìˆ˜ ê³±ì…ˆ-ê°€ì‚° (Integer Multiply-Add) |
  | **14** | **Warp 1: IMAD** | Warp 1ì˜ ì •ìˆ˜ ê³±ì…ˆ-ê°€ì‚° |
  | **15** | **Warp 2: IMAD** | Warp 2ì˜ ì •ìˆ˜ ê³±ì…ˆ-ê°€ì‚° |
  | **16** | **Warp 3: IMAD** | Warp 3ì˜ ì •ìˆ˜ ê³±ì…ˆ-ê°€ì‚° |

  -------------------------
  
  | Cycle | FP32 Units (16 Cores) | ë¹„ê³  |
  | :--- | :--- | :--- |
  | **1** | **Warp 0: FMUL1** (1/2) | Warp 0ì˜ ì•ìª½ 16ê°œ ìŠ¤ë ˆë“œ ì²˜ë¦¬ |
  | **2** | **Warp 0: FMUL1** (2/2) | Warp 0ì˜ ë’¤ìª½ 16ê°œ ìŠ¤ë ˆë“œ ì²˜ë¦¬ (Warp 0 ì™„ë£Œ) |
  | **3** | **Warp 1: FMUL1** (1/2) | Warp 1ì˜ ì•ìª½ 16ê°œ ìŠ¤ë ˆë“œ ì²˜ë¦¬ ì‹œì‘ |
  | **4** | **Warp 1: FMUL1** (2/2) | Warp 1ì˜ ë’¤ìª½ 16ê°œ ìŠ¤ë ˆë“œ ì²˜ë¦¬ ì™„ë£Œ |
  | **5** | **Warp 2: FMUL1** (1/2) | Warp 2 ì²˜ë¦¬ ì‹œì‘ |
  | **6** | **Warp 2: FMUL1** (2/2) | Warp 2 ì²˜ë¦¬ ì™„ë£Œ |
  | **7** | **Warp 3: FMUL1** (1/2) | Warp 3 ì²˜ë¦¬ ì‹œì‘ |
  | **8** | **Warp 3: FMUL1** (2/2) | Warp 3 ì²˜ë¦¬ ì™„ë£Œ |
  | **9** | **Warp 0: FMUL2** (1/2) | Warp 0ì˜ ë‘ ë²ˆì§¸ ëª…ë ¹ì–´ ì‹œì‘ |
  | **10** | **Warp 0: FMUL2** (2/2) | Warp 0ì˜ ë‘ ë²ˆì§¸ ëª…ë ¹ì–´ ì™„ë£Œ |
  | **11** | **Warp 1: FMUL2** (1/2) | Warp 1ì˜ ë‘ ë²ˆì§¸ ëª…ë ¹ì–´ ì‹œì‘ |
  | **12** | **Warp 1: FMUL2** (2/2) | Warp 1ì˜ ë‘ ë²ˆì§¸ ëª…ë ¹ì–´ ì™„ë£Œ |
  | **13** | **Warp 2: FMUL2** (1/2) | Warp 2ì˜ ë‘ ë²ˆì§¸ ëª…ë ¹ì–´ ì‹œì‘ |
  | **14** | **Warp 2: FMUL2** (2/2) | Warp 2ì˜ ë‘ ë²ˆì§¸ ëª…ë ¹ì–´ ì™„ë£Œ |
  | **15** | **Warp 3: FMUL2** (1/2) | Warp 3ì˜ ë‘ ë²ˆì§¸ ëª…ë ¹ì–´ ì‹œì‘ |
  | **16** | **Warp 3: FMUL2** (2/2) | Warp 3ì˜ ë‘ ë²ˆì§¸ ëª…ë ¹ì–´ ì™„ë£Œ |
    
  - scenario 2: memory request, 1 inst. dependency
  ```bash
  # for 4 warps
  FMUL
  ISETP
  LDG.E.SYS
  IMAD (dependent w/ LDG)
  ```

  | Cycle | FP32 Units (32 Cores ê°€ì •) | ë¹„ê³  |
  | :--- | :--- | :--- |
  | **1** | **Warp 0: FMUL** | Warp 0 ì‹œì‘ |
  | **2** | **Warp 1: FMUL** | Warp 1 ì‹œì‘ |
  | **3** | **Warp 2: FMUL** | Warp 2 ì‹œì‘ |
  | **4** | **Warp 3: FMUL** | Warp 3 ì‹œì‘ |
  | **5** | **Warp 0: ISETP** | Warp 0 ë¹„êµ ì—°ì‚° |
  | **6** | **Warp 1: ISETP** | Warp 1 ë¹„êµ ì—°ì‚° |
  | **7** | **Warp 2: ISETP** | Warp 2 ë¹„êµ ì—°ì‚° |
  | **8** | **Warp 3: ISETP** | Warp 3 ë¹„êµ ì—°ì‚° |
  | **9** | **Warp 0: LDG** | Warp 0 ë©”ëª¨ë¦¬ ìš”ì²­ (Stall ì‹œì‘) |
  | **10** | **Warp 1: LDG** | Warp 1 ë©”ëª¨ë¦¬ ìš”ì²­ |
  | **11** | **Warp 2: LDG** | Warp 2 ë©”ëª¨ë¦¬ ìš”ì²­ |
  | **12** | **Warp 3: LDG** | Warp 3 ë©”ëª¨ë¦¬ ìš”ì²­ |
  | **13** | (Memory Waiting) | Warp 0 ë°ì´í„° ì•„ì§ ì•ˆ ì˜´ (Stall) |
  | **14** | (Memory Waiting) | Warp 1 ë°ì´í„° ì•„ì§ ì•ˆ ì˜´ |
  | **15** | **Warp 0: IMAD** | **Warp 0 ë°ì´í„° ë„ì°©!** (IMAD ì‹¤í–‰) |
  | **16** | **Warp 1: IMAD** | **Warp 1 ë°ì´í„° ë„ì°©!** (IMAD ì‹¤í–‰) |

- Summary
  - High occupancy doesn't always equate to high perforamnce
  - Identifying and understanding occupancy can help us pinpoint performance issues.
  - Low occupancy, on the other hand, suggests that there's a bottleneck preventing the GPU from being fully utilized.
 
## Latency Hiding
- CPUì—ì„œëŠ” dependencyë¥¼ ì¡°ì‚¬í•´ì„œ ê¸°ë‹¤ë¦´ í•„ìš”ê°€ ì—†ëŠ” Instructionì´ ë’¤ìª½ì— ìˆìœ¼ë©´ ìˆœì„œë¥¼ ë°”ê¿”ì„œ ì‹¤í–‰í•´ë²„ë¦¬ê¸°ë„ í•¨ (Out of Order)
- DSPì—ì„œëŠ” ë³´í†µ scratch pad memoryë¥¼ ë‘ê¸° ë•Œë¬¸ì— ì—°ì‚°ê¸° ë¿ë§Œ ì•„ë‹ˆë¼ Load/Store ëª…ë ¹ì–´ê¹Œì§€ Cycleì´ Staticí•¨. ê·¸ë˜ì„œ, OoOë³´ë‹¤ëŠ” Compile ë‹¨ê³„ì—ì„œ VLIWë¡œ ì—¬ëŸ¬ ê°œì˜ ëª…ë ¹ì–´ë¥¼ ë¬¶ì–´ë²„ë ¤ì„œ Latency Hidingì„ í•¨.
- GPUëŠ” dependency ë•Œë¬¸ì— stallë˜ëŠ” warpê°€ ìƒê¸°ë©´ ë‹¤ë¥¸ warpë¡œ context switchingí•´ë²„ë¦°ë‹¤ëŠ” ì² í•™

# 28. Allocated active blocks per SM
- ë™ì‹œì— ì‹¤í–‰ê°€ëŠ¥í•œ block ìˆ˜
- ì—¬ëŸ¬ê°€ì§€ HW ìì›ì— ì˜í•´ ê³„ì‚°ë˜ëŠ” block ìˆ˜ ì¤‘ minimum

## Max Thread blocks/SM
- A100 ê¸°ì¤€ 32ê°œ
  
## Max warps/SM
- A100 ê¸°ì¤€ 64ê°œ
- Thread Blockì˜ Sizeì— ë”°ë¼ ëª‡ê°œì˜ Blockì´ SMì— í• ë‹¹ë ì§€ëŠ” ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŒ
- ì˜ˆë¥¼ ë“¤ì–´, í•œ ê°œ Blockì´ 128 Threads (4 Warps)ë¡œ êµ¬ì„±ëœë‹¤ë©´ ì´ SMì—ëŠ” 16ê°œ Blockë§Œ í• ë‹¹ ê°€ëŠ¥
- í•œ ê°œ Blockì´ 64 Threads (2 Warps)ë¡œ êµ¬ì„±ëœë‹¤ë©´ 32ê°œ Blockìœ¼ë¡œ êµ¬ì„± ê°€ëŠ¥

## Max registers/SM
- A100 ê¸°ì¤€ 64Kê°œ
- 1024 Threadsë¡œ êµ¬ì„±ëœ 1 Blockì„ ê°€ì •, Each thread requires 100 registers.
- thread ìˆ˜ë¥¼ ì¤„ì´ì§€ ì•Šìœ¼ë©´ register spilling ë°œìƒ!
- register spillingì´ ë°œìƒí•˜ë©´ registerê°€ ëª¨ìë¼ë¯€ë¡œ local memoryê¹Œì§€ ëŒì–´ì“°ê²Œ ë¨. local memoryëŠ” registerì— ë¹„í•´ latencyê°€ ëŠë¦¬ë¯€ë¡œ performance degradation

## Shared Memory/SM
- A100 ê¸°ì¤€ up to 164KB

# 29. Starting with the nsight compute

# 30. All profiling tools from NVidia (Nsight systems - compute - nvprof ...)
- CUDA-MEMCHECK
  - Identify and diagnose memory errors in CUDA applications
- CUDA-GDB
- NVIDIA Visual Profiler (nvvp)
  - Detailed timing info and hw counters for CUDA, OpenCL, Direct3D...
  - Graphical view of the applications timelines and achieved occupancy
- NVIDIA Nsight Systems
  - Comprehensive workload level performance
- NVIDIA Nsight Compute
  - Dive into top CUDA kernels by using metrics/counter collection
- NVIDIA Nsight Graphics
  - Detailed frame/render performance

# 31. Error Checking APIs
- Checking erros to ensure Cuda functions operate smoothly.
- Example
  - Application compiles correctly, but fails to execute properly
  - Malfunctioning malloc because no enough space in the memory
- Two catergories
  - Synchronous
  - Asynchronous 
- Usage
  ```cpp
  cudaError_t err = cudaMalloc((void **)&d_A, size);
  if (err != cudaSuccess) {
      fprintf(stderr, "Failed to allocated device memory %s\n", cudaGetErrorString(err));
  }

  cudaError_t err = cudaGetLastError();
  if (err != cudaSuccess) {
      fprintf(stderr, "Kernel launch failed %s\n", cudaGetErrorString(err));
  }
  ```

# 32. Nsight Compute performance using command line analysis
## ë‘ ê°€ì§€ ë¶„ì„ ë°©ë²•

| ë°©ë²• | íŠ¹ì§• | ì‚¬ìš© ì‹œê¸° |
| --- | --- | --- |
| **CLI (Command Line)** | íŠ¹ì • ë©”íŠ¸ë¦­ë§Œ ë¹ ë¥´ê²Œ ìˆ˜ì§‘ | ëª‡ ê°€ì§€ ìˆ˜ì¹˜ë§Œ í™•ì¸í•  ë•Œ |
| **GUI (Graphical)** | Roofline ë¶„ì„, ì°¨íŠ¸, ìƒì„¸ ì‹œê°í™” | ì‹¬ì¸µ ì„±ëŠ¥ ë¶„ì„í•  ë•Œ |

**ê¸°ë³¸ ëª…ë ¹ì–´**
```basah
ncu ./my_cuda_app                    # ê¸°ë³¸ 4ê°œ ì„¹ì…˜ ì¶œë ¥
ncu -o profile ./my_cuda_app         # ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥
```

## Sections (ì„¹ì…˜)

ê¸°ë³¸ ì‹¤í–‰ ì‹œ 4ê°œ ì„¹ì…˜ë§Œ í‘œì‹œë˜ì§€ë§Œ,Â **ì´ 23ê°œ ì„¹ì…˜**ì´ ì¡´ì¬í•¨

### ê¸°ë³¸ 4ê°œ ì„¹ì…˜
| ì„¹ì…˜ | ë‚´ìš© |
| --- | --- |
| **GPU Speed of Light** | DRAM, L1/L2 ìºì‹œ throughput, SM utilization |
| **Launch Statistics** | block size, grid size, registers/thread, shared memory |
| **Occupancy** | theoretical vs achieved occupancy |
| **Memory Workload** | DRAM, L1, L2ì˜ active cycles |

### íŠ¹ì • ì„¹ì…˜ë§Œ ë³´ê¸°
```bash
# Launch Statisticsë§Œ ë³´ê¸°
ncu --section LaunchStats ./my_cuda_app

# Warp State Statistics ë³´ê¸°
ncu --section WarpStateStats ./my_cuda_app
```

### ì£¼ìš” ì„¹ì…˜ ëª©ë¡
| Identifier | ì„¤ëª… |
| --- | --- |
| `SpeedOfLight` | GPU ì „ì²´ throughput |
| `LaunchStats` | ì»¤ë„ ëŸ°ì¹˜ ì •ë³´ |
| `Occupancy` | Warp occupancy |
| `MemoryWorkloadAnalysis` | ë©”ëª¨ë¦¬ ì›Œí¬ë¡œë“œ ìƒì„¸ |
| `WarpStateStats` | Warp ìƒíƒœ í†µê³„ |
| `SchedulerStats` | ìŠ¤ì¼€ì¤„ëŸ¬ í†µê³„ |
| `SourceCounters` | ì†ŒìŠ¤ ë ˆë²¨ ì¹´ìš´í„° |
| `NVLink` | NVLink í†µì‹  ë¶„ì„ |


## Metrics (ë©”íŠ¸ë¦­)

> ğŸ’¡ Nsight Computeì—ëŠ”Â ì•½ 10ë§Œ ê°œì˜ ë©”íŠ¸ë¦­ì´ ìˆìŒ
> ì°¸ê³  : https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metric-collection

### ë©”íŠ¸ë¦­ ì „ì²´ ëª©ë¡ ë³´ê¸°

```bash
ncu --query-metrics-mode all > metrics.txt
```

### ë©”íŠ¸ë¦­ ëª…ëª… ê·œì¹™

```jsx
[í•˜ë“œì›¨ì–´ ìœ ë‹›]__[ë©”íŠ¸ë¦­ëª…].[suffix]
```

**ì˜ˆì‹œ**:Â `dram__bytes.avg`

- `dram`Â = í•˜ë“œì›¨ì–´ ìœ ë‹› (DRAM)
- `bytes`Â = ë©”íŠ¸ë¦­ (ë°”ì´íŠ¸ ìˆ˜)
- `avg`Â = suffix (í‰ê· ê°’)

### í•˜ë“œì›¨ì–´ ìœ ë‹›

| ì ‘ë‘ì–´ | í•˜ë“œì›¨ì–´ |
| --- | --- |
| `dram` | DRAM (ê¸€ë¡œë²Œ ë©”ëª¨ë¦¬) |
| `l1tex` | L1 í…ìŠ¤ì²˜ ìºì‹œ |
| `lts` | L2 ìºì‹œ |
| `sm` | Streaming Multiprocessor |
| `smsp` | SM ë‚´ íŒŒí‹°ì…˜ (SMì˜ 1/4) |
| `gpu` | GPU ì „ì²´ |

### Suffix (ì ‘ë¯¸ì‚¬)

| Suffix | ì˜ë¯¸ |
| --- | --- |
| `.min` | ëª¨ë“  SM ì¤‘ ìµœì†Œê°’ |
| `.max` | ëª¨ë“  SM ì¤‘ ìµœëŒ€ê°’ |
| `.avg` | ëª¨ë“  SMì˜ í‰ê· ê°’ |
| `.sum` | ì „ì²´ GPU í•©ê³„ (= max Ã— SM ê°œìˆ˜) |

**ì˜ˆì‹œ**

- 100ê°œ SMì´ ìˆê³  L2 ìºì‹œ ì‚¬ìš© ì‚¬ì´í´ì´ SMë§ˆë‹¤ ë‹¤ë¥¼ ë•Œ:
    - `.min`Â = ê°€ì¥ ì ê²Œ ì‚¬ìš©í•œ SMì˜ ê°’
    - `.max`Â = ê°€ì¥ ë§ì´ ì‚¬ìš©í•œ SMì˜ ê°’
    - `.avg`Â = ì „ì²´ í‰ê· 
    - `.sum`Â = ì „ì²´ í•©ê³„
 
## ì‹¤ì „ ì‚¬ìš©ë²•

### íŠ¹ì • ë©”íŠ¸ë¦­ ìˆ˜ì§‘

```bash
# L1 ìºì‹œ hit rate
ncu --metrics l1tex__t_sector_hit_rate ./my_app

# ì—¬ëŸ¬ ë©”íŠ¸ë¦­ ë™ì‹œ ìˆ˜ì§‘ (ì‰¼í‘œë¡œ êµ¬ë¶„)
ncu --metrics l1tex__t_sector_hit_rate,lts__t_sector_hit_rate ./my_app

# suffix ìƒëµí•˜ë©´ ëª¨ë“  suffix ìˆ˜ì§‘
ncu --metrics sm__inst_executed ./my_app
# â†’ sm__inst_executed.avg, .max, .min, .sum ëª¨ë‘ ì¶œë ¥

```

### CSVë¡œ ë‚´ë³´ë‚´ê¸°

```bash
ncu --metrics sm__inst_executed --csv ./my_app > output.csv

```

### íŠ¹ì • í•˜ë“œì›¨ì–´ ìœ ë‹›ì˜ ëª¨ë“  ë©”íŠ¸ë¦­ ìˆ˜ì§‘

```bash
# shared memory ê´€ë ¨ ëª¨ë“  ë©”íŠ¸ë¦­
ncu --metrics regex:.*shared.* ./my_app --csv > shared_metrics.csv

# L1 ìºì‹œ ê´€ë ¨ ëª¨ë“  ë©”íŠ¸ë¦­
ncu --metrics regex:.*l1tex.* ./my_app
```

---

## í•µì‹¬ ë©”íŠ¸ë¦­ ì˜ˆì‹œ

### ìºì‹œ ì„±ëŠ¥

```bash
# L1 hit rate (0%ë©´ ë¬¸ì œ!)
ncu --metrics l1tex__t_sector_hit_rate ./my_app

# L2 hit rate
ncu --metrics lts__t_sector_hit_rate ./my_app

```

> âš ï¸ L1 hit rateê°€ 0%ë©´ ëª¨ë“  ë©”ëª¨ë¦¬ ì—°ì‚°ì´ ê¸€ë¡œë²Œ ë©”ëª¨ë¦¬ì—ì„œ ì½ëŠ” ê²ƒ
> â†’ ìˆ˜ë°± ì‚¬ì´í´ vs L1 íˆíŠ¸ ì‹œ ~30 ì‚¬ì´í´

### ëª…ë ¹ì–´ ì‹¤í–‰

```bash
# SMë‹¹ ì‹¤í–‰ëœ ëª…ë ¹ì–´ ìˆ˜
ncu --metrics sm__inst_executed ./my_app

# FP64 (double precision) ëª…ë ¹ì–´
ncu --metrics sm__inst_executed_pipe_fp64 ./my_app

# FP16 (half precision) ëª…ë ¹ì–´
ncu --metrics sm__inst_executed_pipe_fp16 ./my_app
```

### Warp ìƒíƒœ

```bash
ncu --section WarpStateStats ./my_app
```

- `warp_cycles_per_issued_instruction`Â - ëª…ë ¹ì–´ë‹¹ warp ì‚¬ì´í´
- `active threads per warp`Â - warpë‹¹ í™œì„± ìŠ¤ë ˆë“œ (ì´ìƒì : 32)

## ë¶„ì„ íŒ

### .sum ê³„ì‚° ë°©ì‹

```jsx
.sum = .max Ã— SM ê°œìˆ˜

```

**ê²€ì¦ ì˜ˆì‹œ**Â (RTX 3060, 38 SM):

```jsx
sm__inst_executed.sum / sm__inst_executed.avg â‰ˆ 38

```

### Nsight Computeê°€ ì£¼ëŠ” ì¡°ì–¸

ì‹¤í–‰ ê²°ê³¼ì— ìë™ìœ¼ë¡œ ë¶„ì„/ê²½ê³ ê°€ í¬í•¨ë¨:

```jsx
The local speedup is 93%, which is good.
On average each warp stalled for 111 cycles due to scoreboard dependency.

```

â†’ ì´ëŸ° ë©”ì‹œì§€ë¥¼ ì½ê³  ë³‘ëª© íŒŒì•…

---

## Quick Reference

| ëª…ë ¹ì–´ | ìš©ë„ |
| --- | --- |
| `ncu ./app` | ê¸°ë³¸ 4ê°œ ì„¹ì…˜ ë¶„ì„ |
| `ncu --section <name> ./app` | íŠ¹ì • ì„¹ì…˜ë§Œ |
| `ncu --metrics <metric> ./app` | íŠ¹ì • ë©”íŠ¸ë¦­ ìˆ˜ì§‘ |
| `ncu --metrics regex:.*<pattern>.* ./app` | íŒ¨í„´ ë§¤ì¹­ ë©”íŠ¸ë¦­ |
| `ncu --csv ./app > out.csv` | CSV ì¶œë ¥ |
| `ncu --query-metrics-mode all` | ì „ì²´ ë©”íŠ¸ë¦­ ëª©ë¡ |
| `ncu -o profile ./app` | ê²°ê³¼ íŒŒì¼ ì €ì¥ (GUIì—ì„œ ì—´ê¸°) |

---

## í•µì‹¬ í¬ì¸íŠ¸

**ì„¹ì…˜ vs ë©”íŠ¸ë¦­**
- ì„¹ì…˜: ê´€ë ¨ ë©”íŠ¸ë¦­ë“¤ì˜ ê·¸ë£¹ (ì˜ˆ: Launch Statistics)
- ë©”íŠ¸ë¦­: ê°œë³„ ì¸¡ì •ê°’ (ì˜ˆ: block size, register count)

**10ë§Œ ê°œ ë©”íŠ¸ë¦­?**

- ì‹¤ì œë¡œ ë‹¤ ë³¼ í•„ìš” ì—†ìŒ
- ëª…ëª… ê·œì¹™ë§Œ ì•Œë©´ 1ë¶„ì— 100ê°œ ë©”íŠ¸ë¦­ íŒŒì•… ê°€ëŠ¥
- í•˜ë“œì›¨ì–´ ìœ ë‹› + ë©”íŠ¸ë¦­ëª… + suffix êµ¬ì¡°

**ì‹¤ì „ì—ì„œ ìì£¼ ë³´ëŠ” ê²ƒ**

- L1/L2 hit rate â†’ ìºì‹œ íš¨ìœ¨
- SM utilization â†’ GPU í™œìš©ë„
- Occupancy â†’ Warp ìŠ¤ì¼€ì¤„ë§ íš¨ìœ¨
- inst_executed â†’ ì‹¤ì œ ì‹¤í–‰ëœ ëª…ë ¹ì–´

### ë°ëª¨ ì‹œë‚˜ë¦¬ì˜¤

- `ncu ./vector_add`Â ì‹¤í–‰í•´ì„œ ê¸°ë³¸ 4ê°œ ì„¹ì…˜ ë³´ì—¬ì£¼ê¸°
- L1 hit rate 0% ë‚˜ì˜¤ëŠ” ê±° ë³´ì—¬ì£¼ê¸° â†’ "ì´ê±´ ë¬¸ì œë‹¤"
- `-csv`ë¡œ Excelì—ì„œ ì—´ì–´ë³´ê¸°

### ë‹¤ìŒ ê°•ì˜ ì˜ˆê³ 

- block/thread ìˆ˜ ë³€ê²½ì´ ì‹¤í–‰ ì‹œê°„ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ ë¶„ì„
- GUI ë¶„ì„ ìƒì„¸ ì„¤ëª…

## ì‹¤ìŠµ ì˜ˆì œ

CLI ë¶„ì„ ì—°ìŠµìš© ì˜ˆì œ:

### 01_vector_add_[basic.cu](http://basic.cu/)

ê¸°ë³¸ Memory Bound ì»¤ë„. CLI ì‚¬ìš©ë²• ìµíˆê¸°ì— ì í•©.

```bash
# ê¸°ë³¸ 4ê°œ ì„¹ì…˜ í™•ì¸
ncu ./01_basic

# íŠ¹ì • ì„¹ì…˜ë§Œ
ncu --section LaunchStats ./01_basic
ncu --section SpeedOfLight ./01_basic

# íŠ¹ì • ë©”íŠ¸ë¦­
ncu --metrics l1tex__t_sector_hit_rate,lts__t_sector_hit_rate ./01_basic

# CSV ì¶œë ¥
ncu --metrics dram__bytes.sum --csv ./01_basic > bandwidth.csv

# GUIìš© íŒŒì¼ ì €ì¥
ncu -o 01_basic_profile ./01_basic

```

### 05_error_[cases.cu](http://cases.cu/)

ì˜ë„ì ìœ¼ë¡œ ì—ëŸ¬ë¥¼ ë°œìƒì‹œí‚¤ëŠ” 6ê°€ì§€ ì¼€ì´ìŠ¤. ncuê°€ ì—ëŸ¬ë¥¼ ì–´ë–»ê²Œ ë³´ê³ í•˜ëŠ”ì§€ í™•ì¸:

```bash
# ê° ì¼€ì´ìŠ¤ë³„ë¡œ ì‹¤í–‰
./05_error 1  # Invalid grid size
./05_error 2  # Invalid block size
./05_error 3  # Too many threads
./05_error 4  # Out of memory
./05_error 5  # Invalid device
./05_error 6  # Kernel timeout

# ncuë¡œ í”„ë¡œíŒŒì¼ë§ ì‹œë„ (ì—ëŸ¬ ë©”ì‹œì§€ í™•ì¸)
ncu ./05_error 3
```

# 33. Graphical Nsight Compute (windows and linux)
